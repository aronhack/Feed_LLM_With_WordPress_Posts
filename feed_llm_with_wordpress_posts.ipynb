{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>How To Find Your Facebook, Instagram, X/Twitte...</td>\n",
       "      <td>&lt;!-- wp:paragraph --&gt;\\n&lt;p&gt;The list below lists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>如何找到自己的Facebook XS Cookie和X/Twitter Auth_Token...</td>\n",
       "      <td>&lt;!-- wp:paragraph --&gt;\\n&lt;p&gt;以下清單列舉了幾個社群平台所使用的Coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>Machine Learning / Deep Learning Algorithm And...</td>\n",
       "      <td>&lt;!-- wp:list {\"ordered\":true} --&gt;\\n&lt;ol&gt;&lt;!-- wp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>機器學習/深度學習演算法與它們的產地，工作與面試的救生指南</td>\n",
       "      <td>&lt;!-- wp:list {\"ordered\":true} --&gt;\\n&lt;ol&gt;&lt;!-- wp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Use Botsonic Chatbot With Rest API</td>\n",
       "      <td>&lt;!-- wp:paragraph --&gt;\\n&lt;p&gt;&lt;a href=\"https://wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>Python Pip/Pipenv Explanation And Most Used Co...</td>\n",
       "      <td>&lt;!-- wp:paragraph --&gt;\\n&lt;p&gt;&lt;code&gt;pip&lt;/code&gt; and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Import A Deep Learning Embedding Model To A Tr...</td>\n",
       "      <td>&lt;!-- wp:paragraph --&gt;\\n&lt;p&gt;Importing embeddings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Run Schedule Jobs Using Mac Automator, An Alte...</td>\n",
       "      <td>&lt;!-- wp:paragraph --&gt;\\n&lt;p&gt;Cron is a well-known...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>Run Llama 2 And Other Open-Source LLM In Pytho...</td>\n",
       "      <td>&lt;!-- wp:heading --&gt;\\n&lt;h2 class=\"wp-block-headi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>在本機Python中執行Llama 2與其他開源大型語言模型</td>\n",
       "      <td>&lt;!-- wp:heading --&gt;\\n&lt;h2 class=\"wp-block-headi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_title  \\\n",
       "1195  How To Find Your Facebook, Instagram, X/Twitte...   \n",
       "1196  如何找到自己的Facebook XS Cookie和X/Twitter Auth_Token...   \n",
       "1270  Machine Learning / Deep Learning Algorithm And...   \n",
       "1271                      機器學習/深度學習演算法與它們的產地，工作與面試的救生指南   \n",
       "1293                 Use Botsonic Chatbot With Rest API   \n",
       "1323  Python Pip/Pipenv Explanation And Most Used Co...   \n",
       "1353  Import A Deep Learning Embedding Model To A Tr...   \n",
       "1365  Run Schedule Jobs Using Mac Automator, An Alte...   \n",
       "1373  Run Llama 2 And Other Open-Source LLM In Pytho...   \n",
       "1378                     在本機Python中執行Llama 2與其他開源大型語言模型   \n",
       "\n",
       "                                           post_content  \n",
       "1195  <!-- wp:paragraph -->\\n<p>The list below lists...  \n",
       "1196  <!-- wp:paragraph -->\\n<p>以下清單列舉了幾個社群平台所使用的Coo...  \n",
       "1270  <!-- wp:list {\"ordered\":true} -->\\n<ol><!-- wp...  \n",
       "1271  <!-- wp:list {\"ordered\":true} -->\\n<ol><!-- wp...  \n",
       "1293  <!-- wp:paragraph -->\\n<p><a href=\"https://wri...  \n",
       "1323  <!-- wp:paragraph -->\\n<p><code>pip</code> and...  \n",
       "1353  <!-- wp:paragraph -->\\n<p>Importing embeddings...  \n",
       "1365  <!-- wp:paragraph -->\\n<p>Cron is a well-known...  \n",
       "1373  <!-- wp:heading -->\\n<h2 class=\"wp-block-headi...  \n",
       "1378  <!-- wp:heading -->\\n<h2 class=\"wp-block-headi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'your_file_path/wp_posts.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Filter posts if you didn't use it in SQL\n",
    "df = df[(df['post_type'] == 'post') & (df['post_status'] == 'publish')]\n",
    "\n",
    "# Convert to string to avoid error caused by NaN\n",
    "df['post_title'] = df['post_title'].astype(str)\n",
    "\n",
    "df[['post_title', 'post_content']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!-- wp:paragraph -->\\n<p>Last week was the long weekend for National Day. I didn\\'t have any outdoor activities because of the final exams of my Master\\'s program and the typhoon. However, I started deploying my project to the Google Cloud Platform in my spare time.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>Previously, I wrote the article\\xa0<em><a href=\"http://localhost:8888/why-is-a-portfolio-website-important-for-a-data-scientist/\">Why Is A Portfolio Website Important For A Data Scientist</a></em>\\xa0to share why I think side project is important for data scientists. The largest of my side projects is on stock price analysis and prediction using Python and machine learning models. This project started at the end of 2020, from preliminary planning to many technical trials and errors, and finally launched in June this year, during the worst time of COVID-19, and started the following PDCA cycle. This project has allowed me to grow substantially in my professional ability, and combining my professional ability with my investment ability has been one of the smartest life decisions I have made recently.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:heading -->\\n<h2><strong>Side Project Can Go Further With Monetization Capabilities</strong></h2>\\n<!-- /wp:heading -->\\n\\n<!-- wp:paragraph -->\\n<p>The sense of accomplishment that finishing a side project is important, and the experience and enhanced expertise are also important. Still, the project can go even further if you can obtain additional value, such as money. A common way to monetize a side project is to offer free web tools to attract traffic and publish advertisements for profit. But actually, getting to this level means that we need to focus our efforts on areas outside of data science, such as running a website and social media. I\\'m bold enough to call stock forecasting the best because it\\'s a project that can monetize and accumulate experience in data analytics and investment operations. Since investment and programming have become mainstream in this era, combining these two learning paths seems natural and logical. Of course, the cost of learning will be very expensive, but it is just like the beauty of the climb over the mountains that is so appealing.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>Some features of the stock price prediction project are noteworthy. First, the more recent predictions should be more accurate from a data prediction viewpoint, such as predicting product sales tomorrow and seven days simultaneously. Theoretically, the former has a higher accuracy rate. When applied to stock investments, this can lead to a short-term style of operation.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>Secondly, the interaction between data and financial markets will result in a paradox: machine learning will work better for more recent predictions, but in investment markets, if the time dimension is too small, it will be easily disturbed by the bumpy ride of the short-term, which will affect the long-term trend judgment.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>The two seem to contradict each other, and I\\'m not sure what kind of adjustment I should make for them. Or just regarding them from a philosophical point of view, then do nothing. Actually, it does not affect the planning and implementation of the project.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>At work, before running each data analysis project, we used to keep asking ourselves, \"What is the final action of this project? \". Most of the time, a project that does not lead to action is worthless. But in the case of stock market analysis, I think it\\'s more appropriate for data scientists to practice their skills because it can be actioned, optimized, and profitable.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:heading -->\\n<h2>Practice To Allocate Resources Like A Business Operator</h2>\\n<!-- /wp:heading -->\\n\\n<!-- wp:paragraph -->\\n<p>The biggest difference between business operators and employees is that operators have the right to allocate the largest amount of resources, including human resources, financial resources, and hardware resources. Therefore, when a side project has profit potential, we can switch to the operator\\'s perspective to evaluate whether to increase investment, allocate investment projects, and even conduct a risk assessment and ROI calculation. I believe this is very helpful in strategic thinking.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>For the stock prediction project, I have two investments, a subscription to the Taiwan Economic Journal (TEJ) database and using the Google Cloud Platform.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:heading {\"level\":3} -->\\n<h3><strong><a href=\"https://eshop.tej.com.tw/E-Shop/\">TEJ Database</a></strong></h3>\\n<!-- /wp:heading -->\\n\\n<!-- wp:paragraph -->\\n<p>Learning to leverage professional partners was one of the most rewarding aspects of my recent growth. There is a lot of free data on the web, but most of them must be collected manually or through a web crawler, both of which require a high investment of time. Web crawlers may seem convenient, but I think it is still a highly labor-intensive task because the website\\'s structure may change, and the server may block the web crawler. And dealing with these occasional mishaps takes a lot of effort, and that\\'s just the first step in the project. The time investment is the most important of all resources, and buying the data directly from someone else is the way to be once and for all. In addition, some open data is released in web or PDF format, such as financial reports, and it can be a long and desperate road to research how to organize the tables on the web into analyzable data by yourself. I\\'ve tried.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:heading {\"level\":3} -->\\n<h3><strong><a href=\"https://cloud.google.com/\">Google Cloud Platform</a></strong></h3>\\n<!-- /wp:heading -->\\n\\n<!-- wp:paragraph -->\\n<p>My computer is a Mac Pro, which normally operates at around 65°C. The picture below showed the temperature of my computer when running models; at the time, the CPU usage rate was 100%, and the temperature was close to an alarming 100°C. Of course, computer overheating can cause the motherboard to burn out and the battery to expand. Both are dangerous and not the situations we want to see. Still, it is a necessary obstacle on the road to personal practice.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:image {\"id\":4804,\"width\":464,\"height\":540,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\\n<figure class=\"wp-block-image size-large is-resized\"><img src=\"http://localhost:8888/wp-content/uploads/mac_pro_temperature.jpg\" alt=\"mac_pro_temperature\" class=\"wp-image-4804\" width=\"464\" height=\"540\"/></figure>\\n<!-- /wp:image -->\\n\\n<!-- wp:paragraph -->\\n<p>There is an additive effect using a paid cloud platform. We are more demanding on the quality and performance of our programming because these platforms usually charge for flow or computation time. The longer the computation time, the higher the cost. At work, when there is not enough time, we usually don\\'t optimize the performance frequently. For example, if a program needs to run for eight hours, we will run the file the day before. But when time is money, and it is the money from our pocket, we will develop new optimization methods even if it beats their brains.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>Big data analysis requires hardware resources and computing power that the average person can\\'t afford on a home computer. Even if you use a desktop computer with good heat dissipation, the computing time may still be so long that it may be a disaster, especially for some modern deep learning algorithms, which are impossible to apply. Fortunately, cloud platforms such as GCP, AWS, and Azure are now very convenient, complete, and completely affordable for the average person, so it is almost as if computing energy is commonplace. Regarding the CPU of a computer, the common specification on the market now is 4-8 cores, but on the cloud platform, we can switch to more powerful machines at any time if needed. According to my current usage, the monthly cost is around 3,000 NTD, but if a side project is not profitable, the 3,000 NTD will be an expense rather than an investment. In this case, I always think about it again and again before I swipe my credit card.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:heading {\"level\":3} -->\\n<h3><strong>Other Services</strong></h3>\\n<!-- /wp:heading -->\\n\\n<!-- wp:paragraph -->\\n<p>If you want to use online opinion data for predictive models, many companies offer this kind of web crawler service, such as Octoparse and Parsehub. Just pay a fee, and you can leverage professional partners to search for data and download it back to your database so that we can focus more on worthy projects, such as public opinion analysis, emotional analysis, and natural language processing. But natural language is also a deep-seated problem, especially in Chinese, where sentence breaks are more complex than in English. Supposing you don\\'t want to plunge into this bottomless abyss, you may want to leverage professional partners again, such as Google and AWS, which both provide natural language analysis services that are easy to use with just a few lines of code. However, all of the above are fee-based services. Let\\'s go back to the main objective of this article, that side project with monetization potential can go farther and has more chances to get in touch with more diverse analytic fields.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>The reasonability of using media content and social media data as a basis for investment is beyond the focus of this article, which can only say that it is technically feasible.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:heading -->\\n<h2>Expanding Software Development Skills</h2>\\n<!-- /wp:heading -->\\n\\n<!-- wp:paragraph -->\\n<p>In terms of work, data analysts, data scientists, data engineers, and so on are usually in their roles due to the division of labor in the organization, but sometimes they can\\'t see the wood for the trees. However, many new challenges will come when side projects become large enough, such as cloud platform management, database and connectivity issues. These tasks may be beyond the scope of a data scientist\\'s defense in a narrow sense, but for a person who wants to see the wood for the trees, I can\\'t think of any other project more suitable for a data scientist to practice.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:heading -->\\n<h2><strong>Conclusion</strong></h2>\\n<!-- /wp:heading -->\\n\\n<!-- wp:paragraph -->\\n<p>Some think the stock market is composed of people and unpredictable human behaviors, so the stock market is also unpredictable. As a result, they do not believe quantitative trading is working. The main difference between the two sides is that the so-called prediction is not the holy grail, which cannot predict the price without bias. It is common to have errors in the prediction, and complete misjudgment often happens, like people reading the daily weather forecast. They will not demand the highest and lowest temperature to be completely accurate because it is unreasonable and impractical. Therefore, how to use the prediction results as the basis within the possible error range to find the most suitable entry and exit timing is the first problem we must face, in addition to the technical side.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>The human brain is probably more accurate than the computer when major, unexpected, difficult to quantify financial events or black swan events occur, such as the COVID-19 epidemic at its worst and U.S. stocks experiencing four circuit breakers in 10 days. We can fully expect the model to fail, this case is indeed more suitable to let the human will override the model, but it is an extreme case. The second problem we must face is whether we should continue to trust the models\\' predictions when other smaller events occur.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>Although prediction models do not always work, in general, as long as the model\\'s prediction results are more accurate than human predictions or significantly reduce the time spent on manual data research, then it will be an available method. Excluding the case of trading bots, data analytics is only an assisted tool, and people still make the final decision. The human-machine synergy is the trend of the AI era. The healthiest mindset is to think of the prediction model as a colleague with great ability, occasional problems, and poor communication skills. How to work with this colleague will require some experience. Even though his work performance is good, he may still lose because of the lack of domain knowledge. We can discuss this in a new post.</p>\\n<!-- /wp:paragraph -->\\n\\n<!-- wp:paragraph -->\\n<p>Finally, I would like to recommend TEJ\\'s database service. I am not publishing an advertisement, and TEJ does not seem to have developed a referral code yet, so this part comes to my mind as a user recommendation. Many international companies provide data services about U.S. stocks or cryptocurrencies, but the market size of Taiwan stocks is much smaller. Among a hundred people, there may not be even one who needs this service. It is not easy to survive in this small and niche market. I hope I can recommend this good service to everyone, and I hope TEJ can operate for a long time, so I don\\'t have to check the health of the web crawler every day.</p>\\n<!-- /wp:paragraph -->'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Content before cleaning\n",
    "chk = df[df['post_title'].str.contains('Stock Market Prediction With')].reset_index(drop=True)\n",
    "chk.loc[0, 'post_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wordpress_content(content):\n",
    "    # Remove WordPress block comments\n",
    "    content_without_comments = re.sub(r'<!-- /wp:.*? -->', '', content)\n",
    "    content_without_comments = re.sub(\n",
    "        r'<!-- wp:.*? -->', '', content_without_comments)\n",
    "\n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(content_without_comments, 'html.parser')\n",
    "\n",
    "    # Extract text from paragraphs and headings\n",
    "    extracted_text = []\n",
    "    for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        extracted_text.append(element.get_text())\n",
    "\n",
    "    # Extract code blocks\n",
    "    for code_block in soup.find_all('pre', class_='wp-block-code'):\n",
    "        extracted_text.append(f\"Code:\\n{code_block.get_text()}\")\n",
    "\n",
    "    # Join the extracted text\n",
    "    full_text = ' '.join(extracted_text)\n",
    "    return full_text\n",
    "\n",
    "\n",
    "def extract_post_content(df=None, file=None, limit=None, output_path=None):\n",
    "    '''\n",
    "    Extract post content from a CSV file.\n",
    "    - Set limit if docuemnts are too many\n",
    "    - Set output_path to save the content to a file\n",
    "    '''\n",
    "    assert df is not None or file is not None, 'Either df or file must be provided'\n",
    "\n",
    "    if file is not None:\n",
    "        df = pd.read_csv(file)\n",
    "        df = (df\n",
    "              .sort_values(by='post_date', ascending=False)\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "    print('Total posts:', len(df))\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "    # Convert to string to avoid error caused by NaN\n",
    "    df['post_title'] = df['post_title'].astype(str)\n",
    "    print(df.head())\n",
    "\n",
    "    post_content = ''\n",
    "    collected_posts = 0\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # Continue when post_content is NaN\n",
    "        if df.loc[i, 'post_content'] != df.loc[i, 'post_content']:\n",
    "            continue\n",
    "\n",
    "        extracted_content = extract_wordpress_content(\n",
    "            df.loc[i, 'post_content'])\n",
    "        post_content += df.loc[i, 'post_title']\n",
    "        post_content += extracted_content\n",
    "        post_content += '=' * 20\n",
    "        collected_posts += 1\n",
    "\n",
    "    print(f'Successfully collected {collected_posts} posts')\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(post_content)\n",
    "    return post_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last week was the long weekend for National Day. I didn't have any outdoor activities because of the final exams of my Master's program and the typhoon. However, I started deploying my project to the Google Cloud Platform in my spare time. Previously, I wrote the article Why Is A Portfolio Website Important For A Data Scientist to share why I think side project is important for data scientists. The largest of my side projects is on stock price analysis and prediction using Python and machine learning models. This project started at the end of 2020, from preliminary planning to many technical trials and errors, and finally launched in June this year, during the worst time of COVID-19, and started the following PDCA cycle. This project has allowed me to grow substantially in my professional ability, and combining my professional ability with my investment ability has been one of the smartest life decisions I have made recently. Side Project Can Go Further With Monetization Capabilities The sense of accomplishment that finishing a side project is important, and the experience and enhanced expertise are also important. Still, the project can go even further if you can obtain additional value, such as money. A common way to monetize a side project is to offer free web tools to attract traffic and publish advertisements for profit. But actually, getting to this level means that we need to focus our efforts on areas outside of data science, such as running a website and social media. I'm bold enough to call stock forecasting the best because it's a project that can monetize and accumulate experience in data analytics and investment operations. Since investment and programming have become mainstream in this era, combining these two learning paths seems natural and logical. Of course, the cost of learning will be very expensive, but it is just like the beauty of the climb over the mountains that is so appealing. Some features of the stock price prediction project are noteworthy. First, the more recent predictions should be more accurate from a data prediction viewpoint, such as predicting product sales tomorrow and seven days simultaneously. Theoretically, the former has a higher accuracy rate. When applied to stock investments, this can lead to a short-term style of operation. Secondly, the interaction between data and financial markets will result in a paradox: machine learning will work better for more recent predictions, but in investment markets, if the time dimension is too small, it will be easily disturbed by the bumpy ride of the short-term, which will affect the long-term trend judgment. The two seem to contradict each other, and I'm not sure what kind of adjustment I should make for them. Or just regarding them from a philosophical point of view, then do nothing. Actually, it does not affect the planning and implementation of the project. At work, before running each data analysis project, we used to keep asking ourselves, \"What is the final action of this project? \". Most of the time, a project that does not lead to action is worthless. But in the case of stock market analysis, I think it's more appropriate for data scientists to practice their skills because it can be actioned, optimized, and profitable. Practice To Allocate Resources Like A Business Operator The biggest difference between business operators and employees is that operators have the right to allocate the largest amount of resources, including human resources, financial resources, and hardware resources. Therefore, when a side project has profit potential, we can switch to the operator's perspective to evaluate whether to increase investment, allocate investment projects, and even conduct a risk assessment and ROI calculation. I believe this is very helpful in strategic thinking. For the stock prediction project, I have two investments, a subscription to the Taiwan Economic Journal (TEJ) database and using the Google Cloud Platform. TEJ Database Learning to leverage professional partners was one of the most rewarding aspects of my recent growth. There is a lot of free data on the web, but most of them must be collected manually or through a web crawler, both of which require a high investment of time. Web crawlers may seem convenient, but I think it is still a highly labor-intensive task because the website's structure may change, and the server may block the web crawler. And dealing with these occasional mishaps takes a lot of effort, and that's just the first step in the project. The time investment is the most important of all resources, and buying the data directly from someone else is the way to be once and for all. In addition, some open data is released in web or PDF format, such as financial reports, and it can be a long and desperate road to research how to organize the tables on the web into analyzable data by yourself. I've tried. Google Cloud Platform My computer is a Mac Pro, which normally operates at around 65°C. The picture below showed the temperature of my computer when running models; at the time, the CPU usage rate was 100%, and the temperature was close to an alarming 100°C. Of course, computer overheating can cause the motherboard to burn out and the battery to expand. Both are dangerous and not the situations we want to see. Still, it is a necessary obstacle on the road to personal practice. There is an additive effect using a paid cloud platform. We are more demanding on the quality and performance of our programming because these platforms usually charge for flow or computation time. The longer the computation time, the higher the cost. At work, when there is not enough time, we usually don't optimize the performance frequently. For example, if a program needs to run for eight hours, we will run the file the day before. But when time is money, and it is the money from our pocket, we will develop new optimization methods even if it beats their brains. Big data analysis requires hardware resources and computing power that the average person can't afford on a home computer. Even if you use a desktop computer with good heat dissipation, the computing time may still be so long that it may be a disaster, especially for some modern deep learning algorithms, which are impossible to apply. Fortunately, cloud platforms such as GCP, AWS, and Azure are now very convenient, complete, and completely affordable for the average person, so it is almost as if computing energy is commonplace. Regarding the CPU of a computer, the common specification on the market now is 4-8 cores, but on the cloud platform, we can switch to more powerful machines at any time if needed. According to my current usage, the monthly cost is around 3,000 NTD, but if a side project is not profitable, the 3,000 NTD will be an expense rather than an investment. In this case, I always think about it again and again before I swipe my credit card. Other Services If you want to use online opinion data for predictive models, many companies offer this kind of web crawler service, such as Octoparse and Parsehub. Just pay a fee, and you can leverage professional partners to search for data and download it back to your database so that we can focus more on worthy projects, such as public opinion analysis, emotional analysis, and natural language processing. But natural language is also a deep-seated problem, especially in Chinese, where sentence breaks are more complex than in English. Supposing you don't want to plunge into this bottomless abyss, you may want to leverage professional partners again, such as Google and AWS, which both provide natural language analysis services that are easy to use with just a few lines of code. However, all of the above are fee-based services. Let's go back to the main objective of this article, that side project with monetization potential can go farther and has more chances to get in touch with more diverse analytic fields. The reasonability of using media content and social media data as a basis for investment is beyond the focus of this article, which can only say that it is technically feasible. Expanding Software Development Skills In terms of work, data analysts, data scientists, data engineers, and so on are usually in their roles due to the division of labor in the organization, but sometimes they can't see the wood for the trees. However, many new challenges will come when side projects become large enough, such as cloud platform management, database and connectivity issues. These tasks may be beyond the scope of a data scientist's defense in a narrow sense, but for a person who wants to see the wood for the trees, I can't think of any other project more suitable for a data scientist to practice. Conclusion Some think the stock market is composed of people and unpredictable human behaviors, so the stock market is also unpredictable. As a result, they do not believe quantitative trading is working. The main difference between the two sides is that the so-called prediction is not the holy grail, which cannot predict the price without bias. It is common to have errors in the prediction, and complete misjudgment often happens, like people reading the daily weather forecast. They will not demand the highest and lowest temperature to be completely accurate because it is unreasonable and impractical. Therefore, how to use the prediction results as the basis within the possible error range to find the most suitable entry and exit timing is the first problem we must face, in addition to the technical side. The human brain is probably more accurate than the computer when major, unexpected, difficult to quantify financial events or black swan events occur, such as the COVID-19 epidemic at its worst and U.S. stocks experiencing four circuit breakers in 10 days. We can fully expect the model to fail, this case is indeed more suitable to let the human will override the model, but it is an extreme case. The second problem we must face is whether we should continue to trust the models' predictions when other smaller events occur. Although prediction models do not always work, in general, as long as the model's prediction results are more accurate than human predictions or significantly reduce the time spent on manual data research, then it will be an available method. Excluding the case of trading bots, data analytics is only an assisted tool, and people still make the final decision. The human-machine synergy is the trend of the AI era. The healthiest mindset is to think of the prediction model as a colleague with great ability, occasional problems, and poor communication skills. How to work with this colleague will require some experience. Even though his work performance is good, he may still lose because of the lack of domain knowledge. We can discuss this in a new post. Finally, I would like to recommend TEJ's database service. I am not publishing an advertisement, and TEJ does not seem to have developed a referral code yet, so this part comes to my mind as a user recommendation. Many international companies provide data services about U.S. stocks or cryptocurrencies, but the market size of Taiwan stocks is much smaller. Among a hundred people, there may not be even one who needs this service. It is not easy to survive in this small and niche market. I hope I can recommend this good service to everyone, and I hope TEJ can operate for a long time, so I don't have to check the health of the web crawler every day.\n"
     ]
    }
   ],
   "source": [
    "extracted_content = extract_wordpress_content(chk.loc[0, 'post_content'])\n",
    "print(extracted_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "04_TW_Industry-Ty8GEq-r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
